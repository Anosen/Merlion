{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotations de manoeuvres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas matplotlib\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from cv2 import norm\n",
    "from numpy import arange\n",
    "\n",
    "import wandb\n",
    "import sys\n",
    "import logging\n",
    "import os\n",
    "from os.path import abspath, dirname, join\n",
    "from genericpath import isfile\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "from pathlib import Path\n",
    "import threading\n",
    "import time\n",
    "from datetime import date, timedelta, datetime\n",
    "import json\n",
    "from httpx import ReadTimeout\n",
    "from re import M\n",
    "import itertools\n",
    "\n",
    "from spacetrack import SpaceTrackClient\n",
    "import spacetrack.operators as op\n",
    "\n",
    "from merlion.models.anomaly.autoencoder import AutoEncoder\n",
    "from merlion.models.anomaly.vae import VAE\n",
    "from merlion.models.anomaly.isolation_forest import IsolationForest\n",
    "from merlion.evaluate.anomaly import TSADMetric\n",
    "from merlion.plot import plot_anoms\n",
    "from merlion.models.factory import ModelFactory\n",
    "from merlion.post_process.threshold import AggregateAlarms\n",
    "from ts_datasets.anomaly import CustomAnomalyDataset\n",
    "from merlion.utils import TimeSeries\n",
    "\n",
    "\n",
    "rootdir = Path().resolve()\n",
    "\n",
    "DORIS_system_maneuvers = pd.read_csv(join(rootdir, 'data', 'maneuvers', 'DORIS_system_maneuvers.csv'), delimiter=\";\")\n",
    "maneuvers_df=DORIS_system_maneuvers.copy()\n",
    "\n",
    "dict_satellites_norad_ids =\t{\n",
    "  \"CRYOSAT2\": 36508,\n",
    "  \"ENVISAT\": 27386,\n",
    "  \"HY2A\": 43682,\n",
    "  \"HY2C\": 46469,\n",
    "  \"HY2D\": 48621,\n",
    "  \"JASON1\": 26997,\n",
    "  \"JASON2\": 33105,\n",
    "  \"JASON3\": 41240, \n",
    "  \"SARAL\": 39086,\n",
    "  \"SENTINEL-3A\": 41335,\n",
    "  \"SENTINEL-3B\": 43437,\n",
    "  \"SENTINEL-6A\": 46984,\n",
    "  \"SPOT2\": 20436,\n",
    "  \"SPOT4\": 25260,\n",
    "  \"SPOT5\": 27421,\n",
    "  \"SWOT\": 54754,\n",
    "}\n",
    "\n",
    "dict_satellites_names =\t{\n",
    "  36508: \"CRYOSAT2\",\n",
    "  27386: \"ENVISAT\",\n",
    "  43682: \"HY2A\",\n",
    "  46469: \"HY2C\",\n",
    "  48621: \"HY2D\",\n",
    "  26997: \"JASON1\",\n",
    "  33105: \"JASON2\",\n",
    "  41240: \"JASON3\", \n",
    "  39086: \"SARAL\",\n",
    "  41335: \"SENTINEL-3A\",\n",
    "  43437: \"SENTINEL-3B\",\n",
    "  46984: \"SENTINEL-6A\",\n",
    "  20436: \"SPOT2\",\n",
    "  25260: \"SPOT4\",\n",
    "  27421: \"SPOT5\",\n",
    "  54754: \"SWOT\",\n",
    "}\n",
    "\n",
    "# Define labels for y-axes\n",
    "parameters_unit = {\n",
    "    \"INCLINATION\": \"(degrees)\",\n",
    "    \"RA_OF_ASC_NODE\": \"(degrees)\",\n",
    "    \"ECCENTRICITY\": \"no unit\",\n",
    "    \"ARG_OF_PERICENTER\": \"(degrees)\",\n",
    "    \"MEAN_ANOMALY\": \"(degrees)\",\n",
    "    \"MEAN_MOTION\": \"(rev. per day)\",\n",
    "    \"APOGEE\": \"km\",\n",
    "    \"PERIGEE\": \"km\",\n",
    "    \"SEMIMAJOR_AXIS\": \"km\"\n",
    "}\n",
    "\n",
    "## Traitement du dataframe\n",
    "# Combine \"Start Date\" and \"Start Hour\" into a single datetime column\n",
    "maneuvers_df['Start DateTime'] = pd.to_datetime(maneuvers_df['Start Date'] + ' ' + maneuvers_df['Start Hour'], format=\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "# Combine \"End Date\" and \"End Hour\" into a single datetime column\n",
    "maneuvers_df['End DateTime'] = pd.to_datetime(maneuvers_df['End Date'] + ' ' + maneuvers_df['End Hour'], format=\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "# Drop rows with NaN values in the \"Maneuver Duration\" column\n",
    "maneuvers_df = maneuvers_df.dropna(subset=['Maneuver Duration'])\n",
    "\n",
    "# Then convert it to time delta (assuming it contains numbers)\n",
    "maneuvers_df['Maneuver Duration Timedelta'] = pd.to_timedelta(maneuvers_df['Maneuver Duration']).dt.total_seconds()\n",
    "\n",
    "# Drop rows with NaN values in the \"Maneuver Duration\" column\n",
    "maneuvers_df = maneuvers_df.dropna(subset=['Start DateTime'])\n",
    "\n",
    "# Add the NoradIds\n",
    "df_satellites_norad_ids = pd.DataFrame(dict_satellites_norad_ids, index=['NoradId']).transpose()\n",
    "maneuvers_df = maneuvers_df.merge(df_satellites_norad_ids, left_on='Satellite', right_index=True)\n",
    "\n",
    "maneuvers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration du dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by the \"Start DateTime\" column\n",
    "sorted_maneuvers_df = maneuvers_df.sort_values(by='Start DateTime').copy()\n",
    "\n",
    "# Create empty dictionaries to store the results for each satellite\n",
    "average_time_steps = {}\n",
    "average_durations = {}\n",
    "mission_durations = {}\n",
    "\n",
    "# Get all unique satellites names\n",
    "satellite_names = sorted_maneuvers_df['Satellite'].unique()\n",
    "\n",
    "# Create a dataframe for mission statistics\n",
    "missions_stats = pd.DataFrame(columns = ['Satellite', 'Start DateTime', 'End DateTime', 'Duration'])\n",
    "\n",
    "# Calculate the average time step for each satellite\n",
    "for satellite_name in satellite_names:\n",
    "    # Get the dataframe of the current satellite maneuvers\n",
    "    satellite_maneuvers_df = sorted_maneuvers_df[sorted_maneuvers_df['Satellite'] == satellite_name].copy()\n",
    "    \n",
    "    # Calculate the time step between all consecutive rows\n",
    "    satellite_maneuvers_df['Time Difference'] = satellite_maneuvers_df['Start DateTime'].diff()\n",
    "    \n",
    "    # Compute the average time step\n",
    "    average_time_step = satellite_maneuvers_df['Time Difference'].mean().round(freq='s')\n",
    "    average_time_steps[satellite_name] = average_time_step\n",
    "    \n",
    "    ## Same thing for maneuver durations\n",
    "    # Convert the \"Maneuver Duration\" column to timedelta\n",
    "    satellite_maneuvers_df['Maneuver Duration'] = pd.to_timedelta(satellite_maneuvers_df['Maneuver Duration'])\n",
    "    \n",
    "    # Compute the average time difference for the current satellite type\n",
    "    average_duration = satellite_maneuvers_df['Maneuver Duration'].mean().round(freq='s')\n",
    "    average_durations[satellite_name] = average_duration\n",
    "    \n",
    "    # Calculate the time range of the satellite mission in orbit\n",
    "    min_maneuver_date = satellite_maneuvers_df['Start DateTime'].min()\n",
    "    max_maneuver_date = satellite_maneuvers_df['End DateTime'].max()\n",
    "    mission_duration = max_maneuver_date-min_maneuver_date\n",
    "    mission_durations[satellite_name] = mission_duration\n",
    "    \n",
    "    # New row data\n",
    "    new_row = {'Satellite' : satellite_name, \n",
    "               'Start DateTime' : min_maneuver_date, \n",
    "               'End DateTime' : max_maneuver_date, \n",
    "               'Duration' : mission_duration}\n",
    "\n",
    "    # Creating a DataFrame for the new row\n",
    "    new_row_df = pd.DataFrame([new_row])\n",
    "\n",
    "    # Concatenating the original DataFrame and the new row DataFrame\n",
    "    missions_stats = pd.concat([missions_stats, new_row_df], ignore_index=True)\n",
    "\n",
    "    \n",
    "\"\"\"     print(f\"{satellite_name}: in orbit between {min_maneuver_date} and {max_maneuver_date} for {mission_duration}\\n\",\n",
    "          f\"Avg maneuver frequency: {average_time_step} | Avg maneuver duration for {satellite_name}: {average_duration}\") \"\"\"\n",
    "missions_stats.sort_values('Duration')\n",
    "display(missions_stats)\n",
    "\n",
    "shortest_mission = min(mission_durations, key=mission_durations.get)\n",
    "print(f\"The shortest mission is {shortest_mission} for {mission_durations[shortest_mission]}\")\n",
    "\n",
    "\n",
    "\n",
    "## Plot maneuvers for all satellites combined\n",
    "\n",
    "# Group the data by \"Satellite\" and then plot the \"Maneuver Duration\" against \"Start Date\"\n",
    "fig, ax = plt.subplots(figsize=(2^16, 2^11))\n",
    "\n",
    "# Define a color map for distinguishing satellites by color\n",
    "#cmap = plt.get_cmap('tab20', len(maneuvers_df['Satellite'].unique()))\n",
    "#colors = itertools.cycle(cmap(np.linspace(0, 1, len(maneuvers_df['Satellite'].unique()))))\n",
    "\n",
    "# Define the colors and the number of shades for each color\n",
    "colors = ['Reds', 'Greens', 'Blues', 'Purples', 'Greys']\n",
    "num_shades = 4\n",
    "\n",
    "# Create a color map with the specified shades\n",
    "color_map = []\n",
    "for color in colors:\n",
    "    for i in range(num_shades):\n",
    "        shade = plt.cm.get_cmap(color)(0.5+i / (num_shades - 1))\n",
    "        color_map.append(shade)\n",
    "\n",
    "colors = itertools.cycle(color_map)\n",
    "\n",
    "lines = itertools.cycle(['solid', 'dotted', 'dashed', 'dashdot'])\n",
    "\n",
    "for satellite, group in maneuvers_df.groupby('Satellite'):\n",
    "    color = next(colors)\n",
    "    line = next(lines)\n",
    "    group.plot(x='Start DateTime', y='Maneuver Duration Timedelta', label=satellite, ax=ax, color=color, linestyle=line)\n",
    "\n",
    "plt.grid(axis='y')\n",
    "ax.set_xlabel(\"Start DateTime\")\n",
    "ax.set_ylabel(\"Maneuver Duration (s)\")\n",
    "mn, mx = ax.get_ylim()\n",
    "ax2 = ax.twinx()\n",
    "ax2.set_ylim(mn/3600, mx/3600)\n",
    "ax2.set_ylabel('Maneuver Duration (h)')\n",
    "plt.title(\"Maneuver Duration vs Maneuver Start Date for DORIS equiped satellites\")\n",
    "legend = ax.legend(loc='upper right')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "## Plot maneuvers for each satellites\n",
    "satellites = maneuvers_df['Satellite'].unique()\n",
    "\n",
    "num_subplots = len(satellites)\n",
    "\n",
    "# Calculate the number of rows and columns for the subplots\n",
    "num_cols = 1  # You can adjust this to the desired number of columns\n",
    "num_rows = (num_subplots + num_cols - 1) // num_cols\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(2^16, 2^16), sharex=True)  # Make subplots share the same x-axis\n",
    "fig.suptitle(\"Maneuver Duration vs Maneuver Start Date for DORIS equiped satellites\")  # Adjust the y parameter to lift the title\n",
    "\n",
    "# Flatten the 2D array of axes for easy indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, satellite in enumerate(satellites):\n",
    "    ax = axes[i]  # Get the current subplot\n",
    "    \n",
    "    # Filter data for the current satellite\n",
    "    data_satellite = maneuvers_df[maneuvers_df['Satellite'] == satellite]\n",
    "    \n",
    "    # Extract x and y data\n",
    "    x = pd.to_datetime(data_satellite['Start DateTime'])\n",
    "    y = data_satellite['Maneuver Duration Timedelta']\n",
    "    \n",
    "    # Create a scatter plot\n",
    "    ax.scatter(x, y, marker=\"+\")\n",
    "    \n",
    "    ax.set_title(f\"{satellite} | Mean frequency: {average_time_steps[satellite]} | Mean duration: {average_durations[satellite]}\")  # Set the title instead of y-axis label\n",
    "    \n",
    "    mn, mx = ax.get_ylim()\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.set_ylim(mn/3600, mx/3600)\n",
    "    ax.grid(True)\n",
    "\n",
    "# Set the common y-axis label (outside the loop)\n",
    "fig.text(0.04, 0.5, 'Maneuver Duration (s)', va='center', rotation='vertical')\n",
    "\n",
    "fig.text(1-0.04, 0.5, 'Maneuver Duration (h)', va='center', rotation='vertical')\n",
    "\n",
    "# Adjust layout\n",
    "fig.tight_layout(rect=[0.045, 0.012, 1-0.045, 0.99])\n",
    "\n",
    "# Create a common x-axis label\n",
    "fig.text(0.5, 0.01, 'Start Date', ha='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Téléchargement des données sur l'API SpaceTrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norad_ids = [36508, 27386, 43682, 46469, 48621, 26997, 33105, 41240, 39086, 41335, 43437, 46984, 20436, 25260, 27421, 54754]\n",
    "\n",
    "def spacetrack_api_query(norad_ids=norad_ids):\n",
    "    # Initialize the Space-Track API client\n",
    "    st = SpaceTrackClient('gregoire.marie08@gmail.com', 'Scarily-Cartridge0-Anything*')\n",
    "\n",
    "    for norad_id in norad_ids:\n",
    "        # Create an empty list to store all queries\n",
    "        all_results = []\n",
    "\n",
    "    \t# Fetch first and last maneuver dates\n",
    "        min_date = maneuvers_df[maneuvers_df['NoradId']==norad_id]['Start DateTime'].min().strftime(\"%Y-%m-%d\")\n",
    "        max_date = maneuvers_df[maneuvers_df['NoradId']==norad_id]['End DateTime'].max().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # Convert min_date and max_date to datetime objects\n",
    "        min_date = datetime.strptime(min_date, \"%Y-%m-%d\") - timedelta(days=7)\n",
    "        max_date = datetime.strptime(max_date, \"%Y-%m-%d\") + timedelta(days=7)\n",
    "        total_epoch = op.inclusive_range(min_date.strftime(\"%Y-%m-%d\"), max_date.strftime(\"%Y-%m-%d\"))\n",
    "        print(f\"\\nTreating {norad_id} between {min_date.strftime(\"%Y-%m-%d\")} & {max_date.strftime(\"%Y-%m-%d\")}\")\n",
    "\n",
    "        mission_duration = max_date - min_date\n",
    "\n",
    "        max_query_span = 5  # In years\n",
    "        # Calculate the number of 5-year intervals\n",
    "        num_intervals = math.ceil((max_date - min_date).days / (365 * max_query_span))\n",
    "\n",
    "        if math.ceil(mission_duration.days / 365) > max_query_span:\n",
    "            print(f\"The mission spans on {mission_duration}, longer than {max_query_span} years. Query split in {num_intervals} intervals\")\n",
    "\n",
    "        # Define the output file name\n",
    "        output_file_name = join(rootdir, 'data', 'tle', 'TLE_{norad_id}_{total_epoch}.json')\n",
    "        \n",
    "        if os.path.exists(output_file_name) and os.path.getsize(output_file_name) > 0:\n",
    "            print(f\"The output file {output_file_name} is not empty.\")\n",
    "        else:\n",
    "            i=0\n",
    "            while i<num_intervals:\n",
    "                # Calculate the start and end dates for each interval\n",
    "                interval_start = (min_date + timedelta(days=i * 365 * max_query_span))\n",
    "                interval_end = (min_date + timedelta(days=(i + 1) * 365 * max_query_span))\n",
    "                if interval_end > max_date:\n",
    "                    interval_end = max_date\n",
    "\n",
    "                # Set the time range to query\n",
    "                query_epoch = op.inclusive_range(interval_start.strftime(\"%Y-%m-%d\"), interval_end.strftime(\"%Y-%m-%d\"))\n",
    "                print(f\"Query #{i}: {query_epoch}\")\n",
    "\n",
    "                try:\n",
    "                    query = st.tle(\n",
    "                        norad_cat_id=norad_id,\n",
    "                        epoch=query_epoch,\n",
    "                        orderby='epoch asc')\n",
    "                    # Append the result to the list\n",
    "                    all_results.extend(query)\n",
    "                    print(f\"Query #{i} successful, data extended.\")\n",
    "                    i+=1\n",
    "                except ReadTimeout as e:\n",
    "                    wait_time=30\n",
    "                    print(f\"Rate limit exceeded, waiting {wait_time}s\")\n",
    "                    time.sleep(wait_time)\n",
    "                except Exception as e:\n",
    "                    print(f\"An exception of type {type(e).__name__} raised in query #{i}:\\n{e.args}\")\n",
    "                    break\n",
    "\n",
    "            assert all_results!=[], f\"No data was fetched for {norad_id}\"\n",
    "            try:\n",
    "                # Save all results as JSON to the output file\n",
    "                with open(output_file_name, 'w') as output_file:\n",
    "                    json.dump(all_results, output_file, indent=2)\n",
    "                    print(f\"All data saved to {output_file_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while saving to {output_file_name}: {e}\")\n",
    "\n",
    "# Query TLEs\n",
    "#spacetrack_api_query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul des résidus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the TLE files are located\n",
    "tle_directory = join(rootdir, 'data', 'tle')\n",
    "\n",
    "# Get the TLE file absolute paths\n",
    "tle_files = [os.path.join(tle_directory, filename) for filename in os.listdir(tle_directory)]\n",
    "    \n",
    "# Create a dictionary to contain the dataframe of each object's residues\n",
    "# Each dataframe contain: \"EPOCH\" (Start Date) as key, \"Inclination residue\", \"Eccentricity residue\", ..., \"Mean Motion residue\", \"Maneuver\", \"Maneuver duration\"\n",
    "residues_df_dict = {}\n",
    "\n",
    "for tle_file in tle_files:\n",
    "    # Read the JSON file\n",
    "    if os.path.isfile(tle_file):\n",
    "        with open(tle_file, 'r') as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        # Sort the data by the \"EPOCH\" field in ascending order\n",
    "        sorted_tle = sorted(data, key=lambda x: x['EPOCH'])\n",
    "\n",
    "        norad_id = sorted_tle[0][\"NORAD_CAT_ID\"]\n",
    "        object_name = sorted_tle[0][\"OBJECT_NAME\"]\n",
    "\n",
    "        # List the parameters we want to keep from the TLE file\n",
    "        parameters = [\"INCLINATION\", \"RA_OF_ASC_NODE\", \"ECCENTRICITY\", \"ARG_OF_PERICENTER\", \"MEAN_ANOMALY\", \"MEAN_MOTION\"] #, \"APOGEE\", \"PERIGEE\", \"SEMIMAJOR_AXIS\"]\n",
    "\n",
    "        # Create a dictionary to store the lists of parameters ordered by EPOCH\n",
    "        parameters_dict = {}\n",
    "\n",
    "        # Extract in a dictionary the values of the parameters from the successive TLEs\n",
    "        for parameter in parameters:\n",
    "            parameters_dict[parameter] = [tle[parameter] for tle in sorted_tle]\n",
    "        \n",
    "        # Transform the \"EPOCH\" of TLEs from strings to datetimes\n",
    "        epochs = [datetime.strptime(tle[\"EPOCH\"], '%Y-%m-%d %H:%M:%S') for tle in sorted_tle]\n",
    "\n",
    "        # Creat a dictionarty to store the lists of residues\n",
    "        residues_dict_tmp = {}\n",
    "        \n",
    "        # Leave out the first epoch to compute residues\n",
    "        residues_dict_tmp[\"EPOCH\"] = epochs[1:]\n",
    "\n",
    "        # Compute differences\n",
    "        for parameter, values in parameters_dict.items():\n",
    "            tmp = []\n",
    "            parameter_residues = []\n",
    "            if parameter in [\"RA_OF_ASC_NODE\",\"MEAN_ANOMALY\",\"ARG_OF_PERICENTER\"]: # Need to take into account the periodicity of the parameters in degree\n",
    "                for i in range(len(values) - 1):\n",
    "                    diff = float(values[i + 1]) - float(values[i])\n",
    "                    tmp.append((diff+180)%360-180)\n",
    "            else:\n",
    "                for i in range(len(values) - 1):\n",
    "                    tmp.append(float(values[i + 1]) - float(values[i]))\n",
    "            residues_dict_tmp[parameter] = tmp\n",
    "        \n",
    "        # Convert the dict to a dataframe with index \"EPOCH\"\n",
    "        residues_df = pd.DataFrame.from_dict(residues_dict_tmp)\n",
    "        residues_df.set_index(\"EPOCH\", inplace=True)\n",
    "\n",
    "        residues_df_dict[norad_id] = residues_df\n",
    "\n",
    "\n",
    "\"\"\" # Fix erroneous values\n",
    "def pop_max(norad_id, parameter_of_max):\n",
    "    object_df = residues_df_dict[norad_id] # Get the dataframe of residues of the object\n",
    "    error_date=abs(object_df[parameter_of_max]).idxmax() # Find the date where the parameter_of_max is max in absolute\n",
    "    print(f\"\\nErroneous value for {norad_id} in {parameter_of_max} at {error_date}:\")\n",
    "    for parameter in parameters:\n",
    "        max_value=object_df[object_df.index==error_date][parameter] # Get the max value of parameter_of_max (for printing)\n",
    "        mean_value=object_df[parameter].mean() # Calculate the mean value to replace it with\n",
    "        print(f\"Replacing {max_value.item()} with {mean_value} for {parameter}\")\n",
    "        object_df[parameter][error_date]=object_df[parameter].mean() # Replace the erroneous with the mean\n",
    "\n",
    "## For JASON3 :\n",
    "pop_max('41240','RA_OF_ASC_NODE')\n",
    "\n",
    "## For SARAL :\n",
    "pop_max('39086','RA_OF_ASC_NODE')\n",
    "pop_max('39086','ARG_OF_PERICENTER') \"\"\"\n",
    "\n",
    "print(f\"residues_df_dict is of type {type(residues_df_dict)} with {len(residues_df_dict)} objects: {list(residues_df_dict.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_df = residues_df_dict[\"25260\"]\n",
    "object_df[(object_df.index>datetime(2004, 10, 12)) & (object_df.index<datetime(2004, 10, 15))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot des résidus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residues(norad_ids=residues_df_dict.keys()): # (1min long)\n",
    "    %matplotlib qt\n",
    "    #%matplotlib inline\n",
    "    norad_ids=[int(id) for id in norad_ids]\n",
    "    for norad_id in norad_ids:\n",
    "        residues_df = residues_df_dict[str(norad_id)]\n",
    "\n",
    "        parameters = residues_df.columns\n",
    "\n",
    "        # Calculate the number of rows and columns for the subplots\n",
    "        num_cols = 1  # You can adjust this to the desired number of columns\n",
    "        num_rows = (len(parameters) + num_cols - 1) // num_cols\n",
    "\n",
    "        # Create subplots\n",
    "        fig, axes = plt.subplots(num_rows, num_cols, figsize=(2^16, 2^16), sharex=True)  # Make subplots share the same x-axis\n",
    "        fig.suptitle(f\"Residues of {dict_satellites_names[int(norad_id)]}, ({norad_id})\")  # Adjust the y parameter to lift the title\n",
    "\n",
    "        x = residues_df.index\n",
    "\n",
    "        for i, parameter in enumerate(parameters):\n",
    "            ax = axes[i]  # Get the current subplot\n",
    "            # Extract x and y data\n",
    "            y = residues_df[parameter]\n",
    "\n",
    "            ax.set_title(f\"{parameter}\")\n",
    "            ax.set_ylabel(f\"{parameters_unit[parameter]}\")\n",
    "            \n",
    "            ax.grid(axis='y', color='black')\n",
    "            \n",
    "            # Create a scatter plot\n",
    "            ax.plot(x, y, marker=\"+\", linewidth = '0.2')\n",
    "            \n",
    "            # Get the dataframe of maneuvers\n",
    "            df_object_maneuvers = maneuvers_df[maneuvers_df['NoradId']==int(norad_id)]\n",
    "            starts = df_object_maneuvers['Start DateTime']\n",
    "            emds = df_object_maneuvers['End DateTime']\n",
    "\n",
    "            # Plot the maneuvers\n",
    "            for index, row in df_object_maneuvers.iterrows():\n",
    "                maneuver_start = row['Start DateTime']\n",
    "                maneuver_end = row['End DateTime']\n",
    "                ax.axvspan(maneuver_start, maneuver_end, facecolor='g', edgecolor='g', alpha=1, lw=0.5, capstyle=\"butt\")\n",
    "            #ax.set_xlim(left=min(x), right=max(x))\n",
    "        # Adjust layout\n",
    "        fig.tight_layout(rect=[0.045, 0.012, 1-0.045, 0.99])\n",
    "        fig.savefig(join(rootdir, 'results', 'residues_maneuvers', 'residues_maneuvers_{dict_satellites_names[int(norad_id)]}_{norad_id}'))\n",
    "\n",
    "#plot_residues([43437])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save residues and maneuvers as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residues_dir = join(rootdir, 'data', 'residues')\n",
    "\n",
    "def export_residues(residues_dir):\n",
    "    norad_ids=[int(id) for id in residues_df_dict.keys()]\n",
    "    norad_ids.sort()\n",
    "    for norad_id in norad_ids:\n",
    "        residues_maneuvers = residues_df_dict[str(norad_id)].copy()\n",
    "        residues_maneuvers.sort_index(inplace=True)\n",
    "        \n",
    "        # Add maneuvers in anomaly column\n",
    "        df_object_maneuvers = maneuvers_df[maneuvers_df['NoradId']==int(norad_id)]\n",
    "        df_object_maneuvers.sort_index(inplace=True)\n",
    "\n",
    "        for index, row in df_object_maneuvers.iterrows():\n",
    "            maneuver_start = row['Start DateTime']\n",
    "            maneuver_end = row['End DateTime']\n",
    "            \n",
    "            extend_after = 3 # days\n",
    "            extend_before = 1 # days\n",
    "            \n",
    "            mask = (residues_maneuvers.index >= (maneuver_start - timedelta(extend_before))) & (residues_maneuvers.index <= (maneuver_end + timedelta(extend_after)))\n",
    "            residues_maneuvers.loc[mask, 'anomaly'] = 1.0\n",
    "            \n",
    "        # Fill the rest of the entries to 0.0 (no anomaly)\n",
    "        residues_maneuvers['anomaly'] = residues_maneuvers['anomaly'].fillna(0.0)\n",
    "        \n",
    "        # Fetch first and last residues dates\n",
    "        min_date = residues_maneuvers.index.min().strftime(\"%Y-%m-%d\")\n",
    "        max_date = residues_maneuvers.index.max().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # Convert min_date and max_date to datetime objects\n",
    "        min_date = datetime.strptime(min_date, \"%Y-%m-%d\")\n",
    "        max_date = datetime.strptime(max_date, \"%Y-%m-%d\")\n",
    "        total_epoch = op.inclusive_range(min_date.strftime(\"%Y-%m-%d\"), max_date.strftime(\"%Y-%m-%d\"))\n",
    "        \n",
    "        save_file = join(rootdir, 'data', 'residues', residues_dir, 'residues_{norad_id}_{total_epoch}.csv')\n",
    "        residues_maneuvers.to_csv(save_file)\n",
    "        print(f'Saved to: {save_file}')\n",
    "        \n",
    "#export_residues(residues_dir=residues_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# st_df_dict = residues_df_dict.copy()\n",
    "\n",
    "# for df_name in st_df_dict.keys():\n",
    "#     residues_df = st_df_dict[df_name]\n",
    "#     print(residues_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sample data\n",
    "# residues_df_tmp = pd.DataFrame({\n",
    "#     'EPOCH': pd.to_datetime(['2023-01-01 00:00:10', '2023-02-01 00:10:00', '2023-03-01 10:00:00']),\n",
    "#     'INCLINATION': [1, 2, 3]\n",
    "# })\n",
    "\n",
    "# maneuvers_df_tmp = pd.DataFrame({\n",
    "#     'Start DateTime': pd.to_datetime(['2023-01-15 00:20:00', '2023-02-15 00:00:30']),\n",
    "#     'Maneuver': ['Maneuver 1', 'Maneuver 2'],\n",
    "#     'Maneuver Type': ['Type1', 'Type2'],\n",
    "#     'Propellant Type': ['Propellant1', 'Propellant2'],\n",
    "#     'Propellant Subtype': ['Subtype1', 'Subtype2'],\n",
    "#     'Propellant Name': ['Name1', 'Name2']\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# residues_df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maneuvers_df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sort the dataframes by EPOCH and Start DateTime\n",
    "# residues_df_tmp = residues_df_tmp.sort_values(by='EPOCH')\n",
    "# maneuvers_df_tmp = maneuvers_df_tmp.sort_values(by='Start DateTime')\n",
    "\n",
    "# # Create a dictionary to map the interval\n",
    "# maneuver_dict = {}\n",
    "# for index, row in maneuvers_df_tmp.iterrows():\n",
    "#     start_time = row['Start DateTime']\n",
    "#     next_index = index + 1\n",
    "\n",
    "#     if next_index < len(maneuvers_df_tmp):\n",
    "#         end_time = maneuvers_df_tmp.loc[next_index, 'Start DateTime']\n",
    "#     else:\n",
    "#         end_time = pd.to_datetime('2100-01-01 00:00:00')  # A very distant future date\n",
    "\n",
    "#     maneuver_dict[(start_time, end_time)] = row['Maneuver']\n",
    "\n",
    "# # Initialize an empty dictionary to store maneuver columns\n",
    "# maneuver_columns = {}\n",
    "\n",
    "# # Iterate through residues_df_tmp and add the Maneuver value\n",
    "# maneuver_column = []\n",
    "# for index, row in residues_df_tmp.iterrows():\n",
    "#     epoch = row['EPOCH']\n",
    "#     matched_maneuver = None\n",
    "\n",
    "#     for interval, maneuver in maneuver_dict.items():\n",
    "#         start_time, end_time = interval\n",
    "#         if start_time <= epoch < end_time:\n",
    "#             matched_maneuver = maneuver\n",
    "#             break\n",
    "\n",
    "#     maneuver_column.append(matched_maneuver)\n",
    "\n",
    "# # Add the 'Maneuver' column to residues_df_tmp\n",
    "# residues_df_tmp['Maneuver'] = maneuver_column\n",
    "\n",
    "# # Iterate through maneuvers_df_tmp to add all columns to residues_df_tmp\n",
    "# for index, row in maneuvers_df_tmp.iterrows():\n",
    "#     start_time = row['Start DateTime']\n",
    "#     next_index = index + 1\n",
    "\n",
    "#     if next_index < len(maneuvers_df_tmp):\n",
    "#         end_time = maneuvers_df_tmp.loc[next_index, 'Start DateTime']\n",
    "#     else:\n",
    "#         end_time = pd.to_datetime('2100-01-01 00:00:00')  # A very distant future date\n",
    "\n",
    "#     interval = (start_time, end_time)\n",
    "\n",
    "#     for col in maneuvers_df_tmp.columns:\n",
    "#         if col != 'Start DateTime':\n",
    "#             maneuver_columns[col] = [row[col] if start_time <= epoch < end_time else None for epoch in residues_df_tmp['EPOCH']]\n",
    "\n",
    "# # Add all columns from maneuvers_df_tmp to residues_df_tmp\n",
    "# for col_name, col_data in maneuver_columns.items():\n",
    "#     residues_df_tmp[col_name] = col_data\n",
    "\n",
    "# residues_df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# residues_df_tmp = st_df_dict[\"20436\"]\n",
    "# residues_df_tmp.reset_index(inplace=True)\n",
    "# maneuvers_df_tmp = maneuvers_df[maneuvers_df['Satellite'] == 'ENVISAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# residues_df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maneuvers_df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sort the dataframes by EPOCH and Start DateTime\n",
    "# residues_df_tmp = residues_df_tmp.sort_values(by='EPOCH')\n",
    "# maneuvers_df_tmp = maneuvers_df_tmp.sort_values(by='Start DateTime')\n",
    "\n",
    "# # Create a dictionary to map the interval\n",
    "# maneuver_dict = {}\n",
    "# for index, row in maneuvers_df_tmp.iterrows():\n",
    "#     start_time = row['Start DateTime']\n",
    "#     next_index = index + 1\n",
    "\n",
    "#     if next_index < len(maneuvers_df_tmp):\n",
    "#         end_time = maneuvers_df_tmp.loc[next_index, 'Start DateTime']\n",
    "#     else:\n",
    "#         end_time = pd.to_datetime('2100-01-01 00:00:00')  # A very distant future date\n",
    "\n",
    "#     maneuver_dict[(start_time, end_time)] = row['Maneuver']\n",
    "\n",
    "# # Iterate through residues_df_tmp and add the Maneuver value\n",
    "# maneuver_column = []\n",
    "# for index, row in residues_df_tmp.iterrows():\n",
    "#     epoch = row['EPOCH']\n",
    "#     matched_maneuver = None\n",
    "\n",
    "#     for interval, maneuver in maneuver_dict.items():\n",
    "#         start_time, end_time = interval\n",
    "#         if start_time <= epoch < end_time:\n",
    "#             matched_maneuver = maneuver\n",
    "#             break\n",
    "\n",
    "#     maneuver_column.append(matched_maneuver)\n",
    "\n",
    "# residues_df_tmp['Maneuver'] = maneuver_column\n",
    "\n",
    "# residues_df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming your dataframes are already sorted by their respective columns\n",
    "# # If not sorted, you can use .sort_values on each dataframe before merging\n",
    "\n",
    "# merged_df = pd.merge_asof(maneuvers_df_tmp, residues_df_tmp, left_on='Start DateTime', right_index=True, direction='forward')\n",
    "\n",
    "# # 'direction' parameter is set to 'forward' to ensure that 'Start DateTime' is between two consecutive 'EPOCH' values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter maneuvers_df for the rows where Satellite is \"ENVISAT\"\n",
    "# maneuvers_df_tmp = maneuvers_df[maneuvers_df['Satellite'] == 'ENVISAT']\n",
    "\n",
    "# # Sort the filtered_maneuvers_df and residues_df by 'Start DateTime' and EPOCH, respectively\n",
    "# filtered_maneuvers_df = maneuvers_df_tmp.sort_values('Start DateTime')\n",
    "# residues_df_tmp = residues_df.sort_index()\n",
    "\n",
    "# # Use merge_asof to merge the dataframes based on 'Start DateTime' and EPOCH\n",
    "# merged_df = pd.merge_asof(residues_df_tmp, filtered_maneuvers_df, left_index=True, right_on='Start DateTime', direction='forward', suffixes=('', '_maneuver'))\n",
    "\n",
    "# # Print the resulting merged dataframe\n",
    "# print(merged_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab_sys843",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
